{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Todo:\n",
    "    • debug and see why all_roots is [] most of the time!\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib3\n",
    "import nltk\n",
    "from util import read_lines, write_lines, dump_pickle, load_pickle\n",
    "import re\n",
    "from functools import reduce\n",
    "from pprint import pprint\n",
    "import itertools\n",
    "import sys\n",
    "from fuzzywuzzy import fuzz\n",
    "from pattern.en import lemma, comparative, superlative\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "debugging = False\n",
    "\n",
    "base_url = \"https://www.etymonline.com/\"\n",
    "# Todo: combine these two\n",
    "match_reg_exp = r'href=\"/word/[a-z\\*-]+\"'\n",
    "href_str = 'href=\"/word/'\n",
    "offset_len = len(href_str)\n",
    "\n",
    "fuzz_threshold = 73 # Lowest so far: \"Kurdish\" vs. \"Kurd\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# string = '<a href=\"/word/-ship\" class=\"crossreference\">'\n",
    "# find_all_occurances(match_reg_exp, string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_content(url):\n",
    "    if not isinstance(url, str):\n",
    "        return None\n",
    "\n",
    "    # Get content\n",
    "    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "    http = urllib3.PoolManager()\n",
    "    try:\n",
    "        response = http.request('GET', url)\n",
    "    except:\n",
    "        print(\"Error in url:\", url)\n",
    "        return None\n",
    "    content = response.data.decode(\"UTF-8\")\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_all_occurances(reg_exp, string):\n",
    "    \"\"\"Find all occurances of start & end indices of in a string based on reg_exp\"\"\"\n",
    "    matches = [m for m in re.findall(reg_exp, string)]\n",
    "    return matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_roots(matches):\n",
    "    roots = [match[offset_len:(-1)] for match in matches]\n",
    "    roots_no_duplicate = list(set(roots))\n",
    "    return roots_no_duplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_top_search_result(word):\n",
    "#     try:\n",
    "    page = 0\n",
    "    \"\"\"we go through each page of the query\"\"\"\n",
    "    while True:\n",
    "        page_str = \"\" if page == 0 else \"page=%d&\" % page\n",
    "        query_url = base_url + \"search?\" + page_str + \"q=\" + word\n",
    "        query_content = get_content(query_url)\n",
    "        if query_content is None:\n",
    "            break\n",
    "        \n",
    "        if \"No results were found\" in query_content:\n",
    "            break\n",
    "        else:\n",
    "            page += 1\n",
    "\n",
    "        truncate_index = query_content.find(\"Trending Words\")\n",
    "        if truncate_index != -1:\n",
    "            query_content = query_content[:truncate_index]\n",
    "\n",
    "        word_start_indices = [m.end() for m in re.finditer(href_str, query_content)]\n",
    "    #     print(word_start_indices)\n",
    "        offsets = [\n",
    "            query_content[word_start_index:].find('\">') \n",
    "            for word_start_index\n",
    "            in word_start_indices]\n",
    "    #     print(query_content[word_start_indices[0]:])\n",
    "    #     input(\"wait\")\n",
    "    #     print(offsets)\n",
    "        for (word_start_index, offset) in zip(word_start_indices, offsets):\n",
    "    #         if offset == -1:\n",
    "    #             continue\n",
    "            searched_word = query_content[word_start_index: (word_start_index + offset)]\n",
    "    #         print(searched_word)\n",
    "            if fuzz.ratio(word, searched_word) >= fuzz_threshold:\n",
    "                url = base_url + \"word/\" + searched_word \n",
    "                return url # returning the first occurance\n",
    "    return None\n",
    "    \n",
    "#         print(matches)\n",
    "#         input(\"continue?\")\n",
    "        \n",
    "#         top_url_start_index = query_content.find(href_str)\n",
    "#         word_start_index = top_url_start_index + offset_len\n",
    "#         top_url_end_offset = query_content[word_start_index:].find('\">')\n",
    "#         top_word = query_content[word_start_index: (word_start_index + top_url_end_offset)]\n",
    "        \n",
    "#         url = base_url + \"word/\" + top_word\n",
    "#     except:\n",
    "#         print(\"Warning: Didn't get top search result for\", word)\n",
    "#         return None\n",
    "        \n",
    "#         top_word = None\n",
    "    \n",
    "#     if top_word is None or (top_word is not None and fuzz.ratio(word, top_word) < fuzz_threshold):\n",
    "#         url = base_url + \"word/\" + word\n",
    "#         print(\"Warning: Didn't get top search result for\", word)\n",
    "#         return None\n",
    "#     else:\n",
    "#         return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "replace_dict = {\n",
    "    \"researcher\": [\"research\", \"-er\"],\n",
    "    \"ultimately\": \"ultimate\",\n",
    "    \"ourselves\": [\"our\", \"self\"],\n",
    "    \"fewer\": \"few\",\n",
    "    \"playoff\": [\"play\", \"off\"],\n",
    "    \"regulatory\": \"regulate\",\n",
    "    \"officially\": \"official\",\n",
    "    \"supplier\": [\"supply\", \"-er\"],\n",
    "    \"closest\": \"close\",\n",
    "    \"learner\": [\"learn\", \"-er\"],\n",
    "    \"dioxide\": [\"di-\", \"oxide\"],\n",
    "    \"nearest\": \"near\",\n",
    "    \"technically\": \"technical\",\n",
    "    \"setup\": \"set-up\",\n",
    "    \"subscale\": [\"sub-\", \"scale\"],\n",
    "    \"collaborative\": \"collaborate\",\n",
    "    \"statewide\": [\"state\", \"wide\"],\n",
    "    \"policymaker\": [\"policy\", \"make\", \"-er\"],\n",
    "    \"linebacker\": [\"line\", \"back\", \"-er\"],\n",
    "    \"fastest\": \"fast\",\n",
    "    \"strangely\": \"strange\",\n",
    "    \"brightly\": \"bright\",\n",
    "    \"deepest\": \"deep\",\n",
    "    \"nutritional\": \"nutrition\",\n",
    "    \"northeastern\": [\"north\", \"eastern\"],\n",
    "    \"wartime\": [\"war\", \"time\"],\n",
    "    \"paid\": \"pay\",\n",
    "    \"dealings\": \"deal\",\n",
    "    \"onstage\": [\"on\", \"stage\"],\n",
    "    \"doctoral\": \"doctor\",\n",
    "    \"turnout\": [\"turn\", \"out\"],\n",
    "    \"computerized\": [\"computer\", \"-ize\"],\n",
    "    \"consciously\": \"conscious\",\n",
    "    \"assistive\": \"assist\",\n",
    "    \"redshift\": [\"red\", \"shift\"],\n",
    "    \"superconducting\": [\"super\", \"conduct\"],\n",
    "    \"wanderer\": [\"wander\", \"-er\"],\n",
    "    \"dichotomous\": \"dichotomy\",\n",
    "    \"stoplight\": [\"stop\", \"light\"],\n",
    "    \"crisply\": \"crisp\",\n",
    "    \"winemaker\": [\"wine\", \"maker\"],\n",
    "    \"apologetically\": \"apologetic\",\n",
    "    \"pilings\": \"piling\",\n",
    "    \"intercut\": [\"inter-\", \"cut\"],\n",
    "    \"descriptor\": \"describe\",\n",
    "    \"governorship\": [\"governor\", \"-ship\"],\n",
    "    \"songwriting\": [\"song\", \"write\"],\n",
    "    \"generalizability\": [\"generalize\", \"-ability\"],\n",
    "    \"walkie\": \"walk\",\n",
    "    \"raiser\": [\"raise\", \"-er\"],\n",
    "    \"redefinition\": \"redefine\",\n",
    "    \"sauté\": \"saute\",\n",
    "    \"curiously\": \"curious\",\n",
    "    \"affective\": \"affect\",\n",
    "    \"attacker\": [\"attack\", \"-er\"],\n",
    "    \"gunfire\": [\"gun\", \"fire\"],\n",
    "    \"goodwill\": [\"good\", \"will\"],\n",
    "    \"spokesperson\": [\"speak\", \"person\"],\n",
    "    \"midwestern\": [\"mid-\", \"western\"],\n",
    "    \"federally\": \"federal\",\n",
    "    \"rename\": [\"re-\", \"name\"],\n",
    "    \"drugstore\": [\"drug\", \"store\"],\n",
    "    \"cloning\": \"clone\",\n",
    "    \"marketer\": \"market\",\n",
    "    \"postseason\": [\"post-\", \"season\"],\n",
    "    \"storyteller\": [\"story\", \"tell\"],\n",
    "    \"uninsured\": [\"un-\", \"insure\"],\n",
    "    \"buyout\": [\"buy\", \"out\"],\n",
    "    \"scorer\": [\"score\"],\n",
    "    \"insofar\": [\"in\", \"so\", \"far\"],\n",
    "    \"midtown\": [\"mid-\", \"town\"],\n",
    "    \"stakeholder\": [\"stake\", \"hold\"],\n",
    "    \"cornerback\": [\"corner\", \"back\"],\n",
    "    \"minivan\": [\"mini-\", \"van\"],\n",
    "    \"Headnote\": [\"head\", \"note\"],\n",
    "    \"cutback\": [\"cut\", \"back\"],\n",
    "    \"preseason\": [\"pre-\", \"season\"],\n",
    "    \"schoolteacher\": [\"school\", \"teach\"],\n",
    "    \"roadway\": [\"road\", \"way\"],\n",
    "    \"Peruvian\": \"Peru\",\n",
    "    \"foothill\": [\"foot\", \"hill\"],\n",
    "    \"backcountry\": [\"back\", \"country\"],\n",
    "    \"exceedingly\": \"exceed\",\n",
    "    \"rearview\": [\"rear\", \"view\"],\n",
    "    \"spearhead\": [\"spear\", \"head\"],\n",
    "    \"schoolchild\": [\"school\", \"child\"],\n",
    "    \"backseat\": [\"back\", \"seat\"],\n",
    "    \"peacekeeper\": [\"peace\", \"keep\"],\n",
    "    \"newsroom\": [\"news\", \"room\"],\n",
    "    \"bookshelf\": [\"book\", \"shelf\"],\n",
    "    \"headset\": [\"head\", \"set\"],\n",
    "    \"fieldwork\": [\"field\", \"work\"],\n",
    "    \"campsite\": [\"camp\", \"site\"],\n",
    "    \"rainforest\": [\"rain\", \"forest\"],\n",
    "    \"songwriter\": [\"song\", \"write\"],\n",
    "    \"lunchtime\": [\"lunch\", \"time\"],\n",
    "    \"rescuer\": [\"rescue\", \"-er\"],\n",
    "    \"fastball\": [\"fast\", \"ball\"],\n",
    "    \"airwaves\": [\"air\", \"wave\"],\n",
    "    \"Frenchman\": [\"French\", \"man\"],\n",
    "    \"matchup\": [\"match\", \"up\"],\n",
    "    \"cheekbone\": [\"cheek\", \"bone\"],\n",
    "    \"preschooler\": \"preschool\",\n",
    "    \"densely\": \"dense\",\n",
    "    \"guidebook\": [\"guide\", \"book\"],\n",
    "    \"airliner\": \"airline\",\n",
    "    \"nonstick\": [\"non-\", \"stick\"],\n",
    "    \"ethnically\": \"ethnic\",\n",
    "    \"battleground\": [\"battle\", \"ground\"],\n",
    "    \"untreated\": [\"un-\", \"treat\"],\n",
    "    \"airway\": [\"air\", \"way\"],\n",
    "    \"correctional\": \"correction\",\n",
    "    \"experimenter\": \"experiment\",\n",
    "    \"multimillion\": [\"multi-\", \"million\"],\n",
    "    \"cameraman\": [\"camera\", \"man\"],\n",
    "    \"airfield\": [\"air\", \"field\"],\n",
    "    \"tabletop\": [\"table\", \"top\"],\n",
    "    \"eagerness\": \"eager\",\n",
    "    \"overestimate\": [\"over-\", \"estimate\"],\n",
    "    \"stockholder\": [\"stock\", \"holder\"],\n",
    "    \"painkiller\": [\"pain\", \"kill\", \"-er\"],\n",
    "    \"observational\": \"observation\",\n",
    "    \"budgetary\": \"budget\",\n",
    "    \"unregulated\": [\"un-\", \"regulate\"],\n",
    "    \"fiberglass\": [\"fiber\", \"glass\"],\n",
    "    \"hotline\": [\"hot\", \"line\"],\n",
    "    \"unease\": [\"un-\", \"ease\"],\n",
    "    \"convincingly\": \"convince\",\n",
    "    \"unspecified\": [\"un-\", \"specify\"],\n",
    "    \"wearily\": \"weary\",\n",
    "    \"wrapping\": \"wrap\",\n",
    "    \"issuer\": \"issue\",\n",
    "    \"mountaintop\": [\"mountain\", \"top\"],\n",
    "    \"goddamned\": [\"god\", \"damn\"],\n",
    "    \"printout\": [\"print\", \"out\"],\n",
    "    \"grudgingly\": \"grudge\",\n",
    "    \"developmentally\": \"development\",\n",
    "    \"floorboard\": [\"floor\", \"board\"],\n",
    "    \"democratically\": \"democrat\",\n",
    "    \"terminally\": \"terminal\",\n",
    "    \"mountainside\": [\"mountain\", \"side\"],\n",
    "    \"biosolids\": [\"bio-\", \"solid\"],\n",
    "    \"airlock\": [\"air\", \"lock\"],\n",
    "    \"sculptural\": \"sculpture\",\n",
    "    \"streetlight\": [\"street\", \"light\"],\n",
    "    \"conspicuously\": \"conspicuous\",\n",
    "    \"footwear\": [\"foot\", \"wear\"],\n",
    "    \"Brazilian\": \"Brazil\",\n",
    "    \"integrative\": \"integrate\",\n",
    "    \"midterm\": [\"mid-\", \"term\"],\n",
    "    \"eyeglass\": [\"eye\", \"glass\"],\n",
    "    \"caseload\": [\"case\", \"load\"],\n",
    "    \"whitetail\": [\"white\", \"tail\"],\n",
    "    \"seawater\": [\"sea\", \"water\"],\n",
    "    \"doorman\": [\"door\", \"man\"],\n",
    "    \"schoolhouse\": [\"school\", \"house\"],\n",
    "    \"riverbank\": [\"river\", \"bank\"],\n",
    "    \"shyness\": [\"shy\", \"-ness\"],\n",
    "    \"trailhead\": [\"trail\", \"head\"],\n",
    "    \"caseworker\": [\"case\", \"worker\"],\n",
    "    \"rationally\": \"rational\",\n",
    "    \"outpace\": [\"out\", \"pace\"], \n",
    "    \"hummingbird\": [\"humming\", \"bird\"],\n",
    "    \"salespeople\": [\"sale\", \"people\"],\n",
    "    \"racetrack\": [\"race\", \"track\"],\n",
    "    \"strikeout\": [\"strike\", \"out\"],\n",
    "    \"treetop\": [\"tree\", \"top\"],\n",
    "    \"skyward\": [\"sky\", \"-ward\"],\n",
    "    \"warplane\": [\"war\", \"plane\"],\n",
    "    \"cottonwood\": [\"cotton\", \"wood\"],\n",
    "    \"stockbroker\": [\"stock\", \"broker\"],\n",
    "    \"violator\": \"violate\",\n",
    "    \"interagency\": [\"inter-\", \"agency\"],\n",
    "    \"scoreboard\": [\"score\", \"board\"],\n",
    "    \"resell\": [\"re-\", \"sell\"],\n",
    "    \"cordless\": [\"cord\", \"-less\"],\n",
    "    \"streetcar\": [\"street\", \"car\"],\n",
    "    \"airfare\": [\"air\", \"fare\"],\n",
    "    \"nightstand\": [\"night\", \"stand\"],\n",
    "    \"evaluator\": \"evaluate\",\n",
    "    \"jumpsuit\": [\"jump\", \"suit\"],\n",
    "    \"coursework\": [\"course\", \"work\"],\n",
    "    \"Panamanian\": [\"Panama\", \"-ian\"],\n",
    "    \"subsystem\": [\"sub-\", \"system\"],\n",
    "    \"factly\": \"fact\",\n",
    "    \"digitally\": \"digital\",\n",
    "    \"leaguer\": \"league\",\n",
    "    \"largemouth\": [\"large\", \"mouth\"],\n",
    "    \"uneasiness\": [\"uneasy\", \"-ness\"],\n",
    "    \"barbershop\": [\"barber\", \"shop\"],\n",
    "    \"worshiper\": \"worship\",\n",
    "    \"curbside\": [\"curb\", \"side\"],\n",
    "    \"airspace\": [\"air\", \"space\"],\n",
    "    \"storybook\": [\"story\", \"book\"],\n",
    "    \"schoolyard\": [\"school\", \"yard\"],\n",
    "    \"weariness\": [\"weary\", \"-ness\"],\n",
    "    \"citywide\": [\"city\", \"wide\"],\n",
    "    \"Darwinian\": [\"Darwin\", \"-ian\"],\n",
    "    \"experimentally\": \"experimental\",\n",
    "    \"crewman\": [\"crew\", \"man\"],\n",
    "    \"gunpoint\": [\"gun\", \"point\"],\n",
    "    \"cornstarch\": [\"corn\", \"starch\"],\n",
    "    \"moviegoer\": [\"movie\", \"go\"],\n",
    "    \"untested\": [\"un-\", \"test\"],\n",
    "    \"grandkid\": [\"grand-\", \"kid\"],\n",
    "    \"intergovernmental\": [\"inter-\", \"governmental\"],\n",
    "    \"bookseller\": [\"book\", \"sell\", \"-er\"],\n",
    "    \"songbird\": [\"song\", \"bird\"],\n",
    "    \"sportswriter\": [\"sport\", \"write\", \"-er\"],\n",
    "    \"truckload\": [\"truck\", \"load\"],\n",
    "    \"crosstalk\": [\"cross\", \"talk\"],\n",
    "    \"framer\": [\"frame\", \"-er\"],\n",
    "    \"graphical\": \"graphic\",\n",
    "    \"schoolwork\": [\"school\", \"work\"],\n",
    "    \"strangeness\": [\"strange\", \"-ness\"],\n",
    "    \"tailback\": [\"tail\", \"back\"],\n",
    "    \"headboard\": [\"head\", \"board\"],\n",
    "    \"councilman\": [\"council\", \"man\"],\n",
    "    \"snowboard\": [\"snow\", \"board\"],\n",
    "    \"supremely\": \"supreme\",\n",
    "    \"retest\": [\"re-\", \"test\"],\n",
    "    \"crosswise\": [\"cross\", \"wise\"],\n",
    "    \"riverboat\": [\"river\", \"boat\"],\n",
    "    \"criminally\": \"criminal\",\n",
    "    \"unrecognized\": [\"un-\", \"recognize\"],\n",
    "    \"airstrike\": [\"air\", \"strike\"],\n",
    "    \"carmaker\": [\"car\", \"make\", \"-er\"],\n",
    "    \"wristwatch\": [\"wrist\", \"watch\"],\n",
    "    \"actuator\": \"actuate\",\n",
    "    \"reassign\": [\"re-\", \"assign\"],\n",
    "    \"rater\": [\"rate\", \"-er\"],\n",
    "    \"discriminant\": [\"discriminate\", \"-ant\"],\n",
    "    \"uncooked\": [\"un-\", \"cook\"],\n",
    "    \"insensitivity\": [\"in-\", \"sensitive\", \"-ity\"],\n",
    "    \"redraw\": [\"re-\", \"draw\"],\n",
    "    \"boldness\": [\"bold\", \"-ness\"],\n",
    "    \"cropland\": [\"crop\", \"land\"],\n",
    "    \"finisher\": [\"finish\", \"-er\"],\n",
    "    \"teacup\": [\"tea\", \"cup\"],\n",
    "    \"jihadist\": [\"jihad\", \"-ist\"],\n",
    "    \"hardcover\": [\"hard\", \"cover\"],\n",
    "    \"dryness\": [\"dry\", \"-ness\"],\n",
    "    \"soundbite\": [\"sound\", \"bite\"],\n",
    "    \"digitize\": [\"digit\", \"-ize\"],\n",
    "    \"friendliness\": [\"friend\", \"-ness\"],\n",
    "    \"snugly\": \"snug\",\n",
    "    \"underfunded\": [\"under\", \"fund\"],\n",
    "    \"feathery\": \"feather\",\n",
    "    \"conservatively\": \"conservative\",\n",
    "    \"saltwater\": [\"salt\", \"water\"],\n",
    "    \"chairmanship\": [\"chairman\", \"-ship\"],\n",
    "    \"darkroom\": [\"dark\", \"room\"],\n",
    "    \"radiologist\": [\"radiology\", \"-ist\"],\n",
    "    \"coveralls\": [\"cover\", \"all\"],\n",
    "    \"vacationer\": [\"vacation\", \"-er\"],\n",
    "    \"infighting\": [\"in\", \"fighting\"],\n",
    "    \"demographer\": [\"demography\", \"-er\"],\n",
    "    \"preoperative\": [\"pre-\", \"operative\"],\n",
    "    \"scorecard\": [\"score\", \"card\"],\n",
    "    \"unraveled\": \"unravel\",\n",
    "    \"upriver\": [\"up\", \"river\"],\n",
    "    \"connectedness\": [\"connected\", \"-ness\"],\n",
    "    \"pillowcase\": [\"pillow\", \"case\"],\n",
    "    \"floodwaters\": [\"flood\", \"water\"],\n",
    "    \"pancreatic\": \"pancrea\",\n",
    "    \"floodplain\": [\"flood\", \"plain\"],\n",
    "    \"newsman\": [\"news\", \"man\"],\n",
    "    \"unscrew\": [\"un-\", \"screw\"],\n",
    "    \"unopened\": [\"un-\", \"open\", \"-ed\"],\n",
    "    \"handset\": [\"hand\", \"set\"],\n",
    "    \"manhunt\": [\"man\", \"hunt\"],\n",
    "    \"supplementation\": [\"supplement\", \"-ation\"],\n",
    "    \"playback\": [\"play\", \"back\"],\n",
    "    \"goodnight\": [\"good\", \"night\"],\n",
    "    \"storeroom\": [\"store\", \"room\"],\n",
    "    \"cooperatively\": [\"cooperative\", \"-ly\"],\n",
    "    \"quarterfinal\": [\"quarter\", \"final\"],\n",
    "    \"wiretap\": [\"wire\", \"tap\"],\n",
    "    \"tightness\": [\"tight\", \"-ness\"],\n",
    "    \"undersecretary\": [\"under-\", \"secretary\"],\n",
    "    \"earphone\": [\"ear\", \"phone\"],\n",
    "    \"washcloth\": [\"wash\", \"cloth\"],\n",
    "    \"nakedness\": [\"naked\", \"-ness\"],\n",
    "    \"vastness\": [\"vast\", \"-ness\"],\n",
    "    \"brainchild\": [\"brain\", \"child\"],\n",
    "    \"reconstructive\": [\"re-\", \"constructive\"],\n",
    "    \"approvingly\": [\"approve\", \"-ing\", \"-ly\"],\n",
    "    \"speechwriter\": [\"speech\", \"writer\"],\n",
    "    \"startlingly\": [\"startle\", \"-ing\", \"-ly\"],\n",
    "    \"backpacker\": [\"backpack\", \"-er\"],\n",
    "    \"defenseman\": [\"defense\", \"man\"],\n",
    "    \"junkyard\": [\"junk\", \"yard\"],\n",
    "    \"Christmastime\": [\"Christmas\", \"time\"],\n",
    "    \"nightlife\": [\"night\", \"life\"],\n",
    "    \"jetliner\": [\"jet\", \"line\", \"-er\"],\n",
    "    \"criminalize\": [\"criminal\", \"-ize\"],\n",
    "    \"unhook\": [\"un-\", \"hook\"],\n",
    "    \"divisional\": [\"division\", \"-al\"],\n",
    "    \"undemocratic\": [\"un-\", \"democratic\"],\n",
    "    \"downwind\": [\"down\", \"wind\"],\n",
    "    \"escaping\": [\"escape\", \"-ing\"],\n",
    "    \"paintbrush\": [\"paint\", \"brush\"],\n",
    "    \"schoolmate\": [\"school\", \"mate\"],\n",
    "    \"rockfish\": [\"rock\", \"fish\"],\n",
    "    \"workbench\": [\"work\", \"bench\"],\n",
    "    \"drumbeat\": [\"drum\", \"beat\"],\n",
    "    \"Shakespearean\": [\"Shakespear\", \"-ean\"],\n",
    "    \"colonizer\": [\"colonize\", \"-er\"],\n",
    "    \"counterweight\": [\"counter-\", \"weight\"],\n",
    "    \"Newtonian\": [\"Newton\", \"-ian\"],\n",
    "    \"Sicilian\": [\"Sicily\", \"-ian\"],\n",
    "    \"endoscopic\": [\"endoscopy\", \"-ic\"],\n",
    "    \"airflow\": [\"air\", \"flow\"]\n",
    "}\n",
    "\n",
    "\"\"\"\n",
    "Why are there two \"mm\"s?\n",
    "\"\"\"\n",
    "abbreviations = [\n",
    "    \"PM\", \"mm\", \"PC\", \"GI\", \"IQ\", \"HMO\", \"GDP\", \"PhD\", \"DJ\", \n",
    "    \"MBA\", \"ANOVA\", \"mmm\", \"MP\", \"IPO\", \"APR\", \"ICU\", \"mm\", \"MRI\",\n",
    "    \"CPA\", \"CFC\", \"ADHD\"\n",
    "]\n",
    "\n",
    "special_words = [\n",
    "    \"mike\",\n",
    "    \"IPod\",\n",
    "    \"y''all\",\n",
    "    \"Qaeda\", # Al-Qaeda 是“基地”组织\n",
    "    \"Chechen\",\n",
    "    \"Salvadoran\",\n",
    "    \"shh\",\n",
    "    \"ahh\",\n",
    "    \"Likert\",\n",
    "    \"Astrodome\",\n",
    "    \"laissez\", # \"laissez faire\" means \"A policy of governmental non-interference in economic affairs\"\n",
    "    \"naw\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_roots(word):\n",
    "    all_roots = [word]\n",
    "    if word in abbreviations + special_words:\n",
    "        return all_roots\n",
    "    \n",
    "    if word in replace_dict.keys():\n",
    "        word = replace_dict[word]\n",
    "    \n",
    "    words = word if isinstance(word, list) else [word]\n",
    "    \n",
    "    roots_lst = []\n",
    "    for word in words:    \n",
    "        word_url = base_url + \"word/\" + word\n",
    "        content = get_content(word_url)\n",
    "        if content is None or \"Error 404 (Not Found)\" in content: # if we haven't found the word\n",
    "            url = base_url + \"word/\" + lemma(word)\n",
    "            content = get_content(url)\n",
    "            if content is None or \"Error 404 (Not Found)\" in content:\n",
    "                url = find_top_search_result(word)\n",
    "                if url is None:\n",
    "                    if (word[(-3):] == \"est\" and superlative(word[:(-3)]) == word): # if it is in superlative form\n",
    "                        url = find_top_search_result(word[:(-3)])\n",
    "                    elif (word[(-2):] == \"er\" and comparative(word[:(-2)]) == word):\n",
    "                        url = find_top_search_result(word[:(-2)])\n",
    "                    else:\n",
    "                        print(\"Warning: Didn't get top search result for\", word)\n",
    "                content = get_content(url)\n",
    "                if content is None or \"Error 404 (Not Found)\" in content:\n",
    "                    continue\n",
    "\n",
    "        # Truncate content\n",
    "        related_entries_index = content.find(\"Related Entries\")\n",
    "        content_truncate = content[:related_entries_index]\n",
    "\n",
    "        matches = find_all_occurances(match_reg_exp, content_truncate) # here content is a byte string\n",
    "\n",
    "        roots = extract_roots(matches)\n",
    "        roots.append(word) # the word itself is obviously a related word\n",
    "        roots_lst.append(roots)\n",
    "\n",
    "    all_roots += list(set(itertools.chain(*roots_lst)))\n",
    "    return list(set(all_roots))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "There are repeated words in word_freq_list, what do we do about it?\n",
    "\"\"\"\n",
    "\n",
    "word_freq_lst = read_lines(\"edited_word_freq_list.txt\")\n",
    "\n",
    "if debugging:\n",
    "    start = 15000\n",
    "    end = 1000000\n",
    "    print(\"Debugging mode on: only process words between index %d and %d\" % (start, end))\n",
    "    word_freq_lst = word_freq_lst[start:end]\n",
    "\n",
    "word_roots_dict = {}\n",
    "for i in tqdm(range(len(word_freq_lst))):\n",
    "    split = word_freq_lst[i].split(\"\\t\")\n",
    "    assert len(split) == 3\n",
    "    word = split[1]\n",
    "    if \"-\" in word: # if it is a compound word with \"-\"\n",
    "        roots = list(\n",
    "            set(list(itertools.chain(*([find_roots(subword) for subword in word.split(\"-\")])))))\n",
    "    else:\n",
    "        roots = find_roots(word)\n",
    "    \n",
    "#     if word in roots:\n",
    "#         roots.remove(word)\n",
    "\n",
    "    word_roots_dict[word] = roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replace_roots_recursive():\n",
    "    changed = False\n",
    "    for word in list(word_roots_dict.keys()):\n",
    "        roots = word_roots_dict[word]\n",
    "        for i in reversed(range(len(roots))):\n",
    "            part = roots[i]\n",
    "            if \"-\" not in part and \"*\" not in part: # we shouldn't extract related words of roots\n",
    "                try:\n",
    "                    word_roots_dict[word][i: (i + 1)] = word_roots_dict[part]\n",
    "                    word_roots_dict[word] = list(set(word_roots_dict[word]))\n",
    "                    changed = True\n",
    "                except:\n",
    "                    pass\n",
    "    return changed\n",
    "\n",
    "max_iter = 5\n",
    "for i in range(max_iter):\n",
    "    changed = replace_roots_recursive()\n",
    "    if not changed:\n",
    "        print(\"Nothing changed after %d iterations.\" % i)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# word_roots_dict = load_pickle(\"word_roots_dict.pkl\")\n",
    "str_lines = []\n",
    "for line in list(word_roots_dict.items()):\n",
    "    str_lines.append(line[0] + \"\\t\" + \", \".join(line[1]))\n",
    "write_lines(\"word_roots_dict.txt\", str_lines)\n",
    "dump_pickle(\"word_roots_dict.pkl\", word_roots_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_roots = list(itertools.chain(*list(word_roots_dict.values())))\n",
    "freq_dist = nltk.FreqDist(all_roots).most_common()\n",
    "write_lines(\"root_freq_dist.txt\", freq_dist)\n",
    "dump_pickle(\"root_freq_dist.pkl\", freq_dist)\n",
    "# print(freq_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
